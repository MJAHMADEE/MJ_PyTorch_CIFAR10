{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNmhgXu7wSOaYbljNzdycVj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MJAHMADEE/PyTorch_CIFAR10/blob/master/MJ_PyTorch_CIFAR10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/MJAHMADEE/PyTorch_CIFAR10.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o6gOvg5oIHn",
        "outputId": "a8aad82a-12b7-4edd-f2fc-132df5611d28"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'PyTorch_CIFAR10'...\n",
            "remote: Enumerating objects: 655, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (42/42), done.\u001b[K\n",
            "remote: Total 655 (delta 50), reused 30 (delta 30), pack-reused 583\u001b[K\n",
            "Receiving objects: 100% (655/655), 6.58 MiB | 13.70 MiB/s, done.\n",
            "Resolving deltas: 100% (245/245), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/PyTorch_CIFAR10/\n",
        "# !python train.py --download_weights 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WqwC6xv7pE_n",
        "outputId": "34f3fcee-6369-4934-d9bd-82cd28f626e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/PyTorch_CIFAR10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --no-cache-dir gdown\n",
        "\n",
        "import gdown\n",
        "import zipfile\n",
        "\n",
        "# Define the URL and output file name\n",
        "url = 'https://drive.google.com/uc?id=17fmN8eQdLpq2jIMQ_X0IXDPXfI9oVWgq'\n",
        "output_file = '/content/data.zip'\n",
        "\n",
        "# Download the file\n",
        "gdown.download(url, output_file, quiet=False)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(output_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content/PyTorch_CIFAR10/cifar10_models/')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DyGUAUMFqqxD",
        "outputId": "f4698379-1993-4986-8a42-0fe2f6d5fc69"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (4.6.6)\n",
            "Collecting gdown\n",
            "  Downloading gdown-4.7.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.12.2)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.27.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from gdown) (1.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.65.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.4.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Installing collected packages: gdown\n",
            "  Attempting uninstall: gdown\n",
            "    Found existing installation: gdown 4.6.6\n",
            "    Uninstalling gdown-4.6.6:\n",
            "      Successfully uninstalled gdown-4.6.6\n",
            "Successfully installed gdown-4.7.1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (uriginal): https://drive.google.com/uc?id=17fmN8eQdLpq2jIMQ_X0IXDPXfI9oVWgq\n",
            "From (redirected): https://drive.google.com/uc?id=17fmN8eQdLpq2jIMQ_X0IXDPXfI9oVWgq&confirm=t&uuid=c02c7954-2615-422f-a5c0-241a1b4e2f4a\n",
            "To: /content/data.zip\n",
            "100%|██████████| 979M/979M [00:07<00:00, 134MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBOtDDqMn8od",
        "outputId": "ae744400-f4ca-4ed1-937f-08ebe4b3c6f2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (4): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (10): ReLU(inplace=True)\n",
              "    (11): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (15): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (16): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (17): ReLU(inplace=True)\n",
              "    (18): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (19): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (22): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (23): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (24): ReLU(inplace=True)\n",
              "    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (26): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from cifar10_models.vgg import vgg11_bn, vgg13_bn, vgg16_bn, vgg19_bn\n",
        "\n",
        "# Untrained model\n",
        "my_model = vgg11_bn()\n",
        "\n",
        "# Pretrained model\n",
        "my_model = vgg11_bn(pretrained=True)\n",
        "my_model.eval() # for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-lightning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "devOojqeXbe_",
        "outputId": "e87d3d56-2186-4c6b-c7bd-cd52b51228b9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.0.4-py3-none-any.whl (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.2/721.2 kB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.22.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.65.0)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0)\n",
            "Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.6.3)\n",
            "Collecting lightning-utilities>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch-lightning) (2.27.1)\n",
            "Collecting aiohttp!=4.0.0a0,!=4.0.0a1 (from fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch-lightning) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch-lightning) (16.0.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning) (2.0.12)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch-lightning)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch-lightning) (2.1.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (2023.5.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning) (3.4)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch-lightning\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch-lightning-2.0.4 torchmetrics-0.11.4 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --classifier vgg16_bn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XqCvXXASXRc-",
        "outputId": "832d37dc-0fc9-4f16-c8c5-eb836484a829"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 0\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: cifar10/vgg16_bn\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type             | Params\n",
            "-----------------------------------------------\n",
            "0 | model     | VGG              | 33.6 M\n",
            "1 | criterion | CrossEntropyLoss | 0     \n",
            "-----------------------------------------------\n",
            "33.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "33.6 M    Total params\n",
            "134.587   Total estimated model params size (MB)\n",
            "2023-06-24 14:10:47.230934: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-24 14:10:48.566978: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Sanity Checking: 0it [00:00, ?it/s]Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data/huy/cifar10/cifar-10-python.tar.gz\n",
            "\n",
            "  0% 0/170498071 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 65536/170498071 [00:00<07:45, 366161.64it/s]\u001b[A\n",
            "  0% 229376/170498071 [00:00<04:09, 681914.88it/s]\u001b[A\n",
            "  0% 720896/170498071 [00:00<01:24, 2012394.55it/s]\u001b[A\n",
            "  1% 1835008/170498071 [00:00<00:42, 3958190.25it/s]\u001b[A\n",
            "  3% 4685824/170498071 [00:00<00:15, 10485168.84it/s]\u001b[A\n",
            "  5% 8421376/170498071 [00:00<00:09, 17871369.84it/s]\u001b[A\n",
            "  7% 12124160/170498071 [00:00<00:06, 23266781.78it/s]\u001b[A\n",
            "  9% 15859712/170498071 [00:01<00:05, 27304849.11it/s]\u001b[A\n",
            " 11% 19202048/170498071 [00:01<00:05, 25422804.16it/s]\u001b[A\n",
            " 14% 23199744/170498071 [00:01<00:05, 29293716.48it/s]\u001b[A\n",
            " 15% 26345472/170498071 [00:01<00:04, 29122012.19it/s]\u001b[A\n",
            " 17% 29753344/170498071 [00:01<00:04, 30474929.61it/s]\u001b[A\n",
            " 20% 33488896/170498071 [00:01<00:04, 32408795.29it/s]\u001b[A\n",
            " 22% 37027840/170498071 [00:01<00:04, 33239561.02it/s]\u001b[A\n",
            " 24% 40828928/170498071 [00:01<00:03, 34610176.41it/s]\u001b[A\n",
            " 26% 44367872/170498071 [00:01<00:03, 32253048.76it/s]\u001b[A\n",
            " 28% 48136192/170498071 [00:02<00:04, 30478552.72it/s]\u001b[A\n",
            " 30% 51904512/170498071 [00:02<00:03, 32372179.34it/s]\u001b[A\n",
            " 33% 55640064/170498071 [00:02<00:03, 33739245.01it/s]\u001b[A\n",
            " 35% 59179008/170498071 [00:02<00:03, 34200263.39it/s]\u001b[A\n",
            " 37% 62685184/170498071 [00:02<00:03, 34379659.70it/s]\u001b[A\n",
            " 39% 66158592/170498071 [00:02<00:03, 34169256.63it/s]\u001b[A\n",
            " 41% 69894144/170498071 [00:02<00:03, 31505967.69it/s]\u001b[A\n",
            " 43% 73138176/170498071 [00:02<00:03, 30700507.11it/s]\u001b[A\n",
            " 45% 76513280/170498071 [00:02<00:02, 31532530.51it/s]\u001b[A\n",
            " 47% 80216064/170498071 [00:03<00:02, 33068954.80it/s]\u001b[A\n",
            " 49% 83918848/170498071 [00:03<00:02, 34075111.91it/s]\u001b[A\n",
            " 51% 87621632/170498071 [00:03<00:02, 34908830.52it/s]\u001b[A\n",
            " 54% 91357184/170498071 [00:03<00:02, 35606854.98it/s]\u001b[A\n",
            " 56% 94961664/170498071 [00:03<00:02, 31769150.62it/s]\u001b[A\n",
            " 58% 98238464/170498071 [00:03<00:02, 31818673.10it/s]\u001b[A\n",
            " 60% 101580800/170498071 [00:03<00:02, 31971067.83it/s]\u001b[A\n",
            " 62% 104923136/170498071 [00:03<00:02, 32334785.93it/s]\u001b[A\n",
            " 63% 108199936/170498071 [00:03<00:01, 32137896.77it/s]\u001b[A\n",
            " 65% 111542272/170498071 [00:03<00:01, 32501604.86it/s]\u001b[A\n",
            " 68% 115245056/170498071 [00:04<00:01, 33818648.43it/s]\u001b[A\n",
            " 70% 119013376/170498071 [00:04<00:01, 34926250.94it/s]\u001b[A\n",
            " 72% 122617856/170498071 [00:04<00:01, 32494212.71it/s]\u001b[A\n",
            " 74% 125992960/170498071 [00:04<00:01, 32796843.35it/s]\u001b[A\n",
            " 76% 129728512/170498071 [00:04<00:01, 34090824.00it/s]\u001b[A\n",
            " 78% 133169152/170498071 [00:04<00:01, 33176290.82it/s]\u001b[A\n",
            " 80% 136577024/170498071 [00:04<00:01, 33431784.31it/s]\u001b[A\n",
            " 82% 139952128/170498071 [00:04<00:00, 32973859.69it/s]\u001b[A\n",
            " 84% 143294464/170498071 [00:04<00:00, 32550403.69it/s]\u001b[A\n",
            " 86% 146604032/170498071 [00:05<00:00, 32702005.93it/s]\u001b[A\n",
            " 88% 150306816/170498071 [00:05<00:00, 33956293.51it/s]\u001b[A\n",
            " 90% 153878528/170498071 [00:05<00:00, 34469797.56it/s]\u001b[A\n",
            " 92% 157351936/170498071 [00:05<00:00, 32901073.68it/s]\u001b[A\n",
            " 94% 160727040/170498071 [00:05<00:00, 32784108.33it/s]\u001b[A\n",
            " 96% 164036608/170498071 [00:05<00:00, 32276370.02it/s]\u001b[A\n",
            "100% 170498071/170498071 [00:05<00:00, 29685589.34it/s]\n",
            "Extracting /data/huy/cifar10/cifar-10-python.tar.gz to /data/huy/cifar10\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Files already downloaded and verified\n",
            "Epoch 0: 100% 196/196 [00:24<00:00,  7.87it/s, v_num=0, loss/train=1.260]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 11.47it/s]\u001b[A\n",
            "Epoch 0: 100% 196/196 [00:28<00:00,  6.88it/s, v_num=0, loss/train=1.260, loss/val=1.390, acc/val=0.489]\n",
            "Epoch 1: 100% 196/196 [00:25<00:00,  7.72it/s, v_num=0, loss/train=1.180, loss/val=1.390, acc/val=0.489]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 12.66it/s]\u001b[A\n",
            "Epoch 1: 100% 196/196 [00:28<00:00,  6.79it/s, v_num=0, loss/train=1.180, loss/val=1.070, acc/val=0.618]\n",
            "Epoch 2: 100% 196/196 [00:25<00:00,  7.66it/s, v_num=0, loss/train=1.050, loss/val=1.070, acc/val=0.618]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 15.51it/s]\u001b[A\n",
            "Epoch 2: 100% 196/196 [00:28<00:00,  6.84it/s, v_num=0, loss/train=1.050, loss/val=1.200, acc/val=0.604]\n",
            "Epoch 3: 100% 196/196 [00:25<00:00,  7.69it/s, v_num=0, loss/train=1.040, loss/val=1.200, acc/val=0.604]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 13.87it/s]\u001b[A\n",
            "Epoch 3: 100% 196/196 [00:28<00:00,  6.87it/s, v_num=0, loss/train=1.040, loss/val=0.871, acc/val=0.706]\n",
            "Epoch 4: 100% 196/196 [00:25<00:00,  7.67it/s, v_num=0, loss/train=0.669, loss/val=0.871, acc/val=0.706]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 15.77it/s]\u001b[A\n",
            "Epoch 4: 100% 196/196 [00:28<00:00,  6.85it/s, v_num=0, loss/train=0.669, loss/val=0.845, acc/val=0.717]\n",
            "Epoch 5: 100% 196/196 [00:25<00:00,  7.55it/s, v_num=0, loss/train=0.685, loss/val=0.845, acc/val=0.717]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 14.38it/s]\u001b[A\n",
            "Epoch 5: 100% 196/196 [00:28<00:00,  6.78it/s, v_num=0, loss/train=0.685, loss/val=0.724, acc/val=0.757]\n",
            "Epoch 6: 100% 196/196 [00:26<00:00,  7.50it/s, v_num=0, loss/train=0.436, loss/val=0.724, acc/val=0.757]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 15.92it/s]\u001b[A\n",
            "Epoch 6: 100% 196/196 [00:29<00:00,  6.74it/s, v_num=0, loss/train=0.436, loss/val=0.745, acc/val=0.747]\n",
            "Epoch 7: 100% 196/196 [00:26<00:00,  7.45it/s, v_num=0, loss/train=0.473, loss/val=0.745, acc/val=0.747]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 15.33it/s]\u001b[A\n",
            "Epoch 7: 100% 196/196 [00:29<00:00,  6.68it/s, v_num=0, loss/train=0.473, loss/val=0.598, acc/val=0.795]\n",
            "Epoch 8: 100% 196/196 [00:26<00:00,  7.44it/s, v_num=0, loss/train=0.534, loss/val=0.598, acc/val=0.795]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 14.91it/s]\u001b[A\n",
            "Epoch 8: 100% 196/196 [00:29<00:00,  6.68it/s, v_num=0, loss/train=0.534, loss/val=0.626, acc/val=0.787]\n",
            "Epoch 9: 100% 196/196 [00:26<00:00,  7.27it/s, v_num=0, loss/train=0.507, loss/val=0.626, acc/val=0.787]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 14.57it/s]\u001b[A\n",
            "Epoch 9: 100% 196/196 [00:29<00:00,  6.55it/s, v_num=0, loss/train=0.507, loss/val=0.548, acc/val=0.817]\n",
            "Epoch 10:   0% 0/196 [00:00<?, ?it/s, v_num=0, loss/train=0.507, loss/val=0.548, acc/val=0.817]Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7ff9b581fc70>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
            "    self._shutdown_workers()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
            "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/process.py\", line 149, in join\n",
            "    res = self._popen.wait(timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/popen_fork.py\", line 40, in wait\n",
            "    if not wait([self.sentinel], timeout):\n",
            "  File \"/usr/lib/python3.10/multiprocessing/connection.py\", line 931, in wait\n",
            "    ready = selector.select(timeout)\n",
            "  File \"/usr/lib/python3.10/selectors.py\", line 416, in select\n",
            "    fd_event_list = self._selector.poll(timeout)\n",
            "KeyboardInterrupt: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n",
            "    data = self._data_queue.get(timeout=timeout)\n",
            "  File \"/usr/lib/python3.10/multiprocessing/queues.py\", line 114, in get\n",
            "    raise Empty\n",
            "_queue.Empty\n",
            "\n",
            "The above exception was the direct cause of the following exception:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/PyTorch_CIFAR10/train.py\", line 92, in <module>\n",
            "    main(args)\n",
            "  File \"/content/PyTorch_CIFAR10/train.py\", line 51, in main\n",
            "    trainer.fit(model, data)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 531, in fit\n",
            "    call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 42, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 570, in _fit_impl\n",
            "    self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1018, in _run_stage\n",
            "    self.fit_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 201, in run\n",
            "    self.advance()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py\", line 354, in advance\n",
            "    self.epoch_loop.run(self._data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 133, in run\n",
            "    self.advance(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/training_epoch_loop.py\", line 189, in advance\n",
            "    batch = next(data_fetcher)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\", line 136, in __next__\n",
            "    self._fetch_next_batch(self.dataloader_iter)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fetchers.py\", line 150, in _fetch_next_batch\n",
            "    batch = next(iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 284, in __next__\n",
            "    out = next(self._iterator)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/combined_loader.py\", line 65, in __next__\n",
            "    out[i] = next(self.iterators[i])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n",
            "    idx, data = self._get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1294, in _get_data\n",
            "    success, data = self._try_get_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\", line 1145, in _try_get_data\n",
            "    raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str)) from e\n",
            "RuntimeError: DataLoader worker (pid(s) 2570, 2574, 2576, 2578) exited unexpectedly\n",
            "Epoch 10:   0%|          | 0/196 [00:05<?, ?it/s, v_num=0, loss/train=0.507, loss/val=0.548, acc/val=0.817]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --classifier vgg16_bn --max_epochs 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxsRZFpyJ0I1",
        "outputId": "fd9282a3-cd47-42b4-d70e-41da817ac84c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 0\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Missing logger folder: cifar10/vgg16_bn\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name      | Type             | Params\n",
            "-----------------------------------------------\n",
            "0 | model     | VGG              | 33.6 M\n",
            "1 | criterion | CrossEntropyLoss | 0     \n",
            "-----------------------------------------------\n",
            "33.6 M    Trainable params\n",
            "0         Non-trainable params\n",
            "33.6 M    Total params\n",
            "134.587   Total estimated model params size (MB)\n",
            "2023-06-24 16:05:51.402094: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-24 16:05:52.370922: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Sanity Checking: 0it [00:00, ?it/s]Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to /data/huy/cifar10/cifar-10-python.tar.gz\n",
            "\n",
            "  0% 0/170498071 [00:00<?, ?it/s]\u001b[A\n",
            "  0% 32768/170498071 [00:00<18:08, 156591.33it/s]\u001b[A\n",
            "  0% 65536/170498071 [00:00<18:05, 156969.10it/s]\u001b[A\n",
            "  0% 98304/170498071 [00:00<18:04, 157108.94it/s]\u001b[A\n",
            "  0% 229376/170498071 [00:00<08:16, 342714.59it/s]\u001b[A\n",
            "  0% 458752/170498071 [00:01<04:36, 614942.22it/s]\u001b[A\n",
            "  1% 917504/170498071 [00:01<02:27, 1153037.23it/s]\u001b[A\n",
            "  1% 1835008/170498071 [00:01<01:16, 2212254.26it/s]\u001b[A\n",
            "  2% 3702784/170498071 [00:01<00:38, 4352084.14it/s]\u001b[A\n",
            "  4% 6815744/170498071 [00:01<00:21, 7653493.42it/s]\u001b[A\n",
            "  6% 9961472/170498071 [00:02<00:16, 9921459.76it/s]\u001b[A\n",
            "  8% 13074432/170498071 [00:02<00:13, 11432337.67it/s]\u001b[A\n",
            " 10% 16220160/170498071 [00:02<00:12, 12526299.78it/s]\u001b[A\n",
            " 11% 19333120/170498071 [00:02<00:11, 13281724.54it/s]\u001b[A\n",
            " 13% 22478848/170498071 [00:02<00:10, 13779536.10it/s]\u001b[A\n",
            " 15% 25624576/170498071 [00:03<00:10, 14115767.60it/s]\u001b[A\n",
            " 17% 28737536/170498071 [00:03<00:09, 14368618.60it/s]\u001b[A\n",
            " 19% 31883264/170498071 [00:03<00:09, 14542289.85it/s]\u001b[A\n",
            " 21% 34996224/170498071 [00:03<00:09, 14714934.83it/s]\u001b[A\n",
            " 22% 38141952/170498071 [00:03<00:08, 14763375.74it/s]\u001b[A\n",
            " 24% 41254912/170498071 [00:04<00:08, 14857290.90it/s]\u001b[A\n",
            " 26% 44400640/170498071 [00:04<00:08, 14823434.00it/s]\u001b[A\n",
            " 28% 47513600/170498071 [00:04<00:08, 14941574.26it/s]\u001b[A\n",
            " 30% 50659328/170498071 [00:04<00:08, 14921033.18it/s]\u001b[A\n",
            " 31% 52789248/170498071 [00:04<00:07, 15969963.32it/s]\u001b[A\n",
            " 32% 54493184/170498071 [00:05<00:08, 13807680.60it/s]\u001b[A\n",
            " 33% 56918016/170498071 [00:05<00:07, 15006706.84it/s]\u001b[A\n",
            " 34% 58523648/170498071 [00:05<00:07, 14986040.85it/s]\u001b[A\n",
            " 35% 60096512/170498071 [00:05<00:08, 12772338.35it/s]\u001b[A\n",
            " 37% 63111168/170498071 [00:05<00:06, 15559922.57it/s]\u001b[A\n",
            " 38% 64782336/170498071 [00:05<00:06, 15233536.25it/s]\u001b[A\n",
            " 39% 66387968/170498071 [00:05<00:08, 12883614.24it/s]\u001b[A\n",
            " 41% 69271552/170498071 [00:06<00:06, 15783499.33it/s]\u001b[A\n",
            " 42% 70975488/170498071 [00:06<00:06, 15066683.99it/s]\u001b[A\n",
            " 43% 72581120/170498071 [00:06<00:07, 12726529.77it/s]\u001b[A\n",
            " 44% 75169792/170498071 [00:06<00:07, 12619901.19it/s]\u001b[A\n",
            " 46% 78282752/170498071 [00:06<00:06, 13407280.42it/s]\u001b[A\n",
            " 48% 81428480/170498071 [00:07<00:06, 13737478.34it/s]\u001b[A\n",
            " 50% 84541440/170498071 [00:07<00:06, 14289957.68it/s]\u001b[A\n",
            " 51% 87654400/170498071 [00:07<00:05, 14053327.25it/s]\u001b[A\n",
            " 53% 90800128/170498071 [00:07<00:05, 14341505.70it/s]\u001b[A\n",
            " 55% 93913088/170498071 [00:07<00:05, 14510227.06it/s]\u001b[A\n",
            " 57% 97026048/170498071 [00:08<00:05, 14611604.28it/s]\u001b[A\n",
            " 59% 100073472/170498071 [00:08<00:04, 14196719.95it/s]\u001b[A\n",
            " 61% 103186432/170498071 [00:08<00:04, 14401957.43it/s]\u001b[A\n",
            " 62% 106332160/170498071 [00:08<00:04, 14570501.81it/s]\u001b[A\n",
            " 64% 109477888/170498071 [00:08<00:04, 14596092.24it/s]\u001b[A\n",
            " 66% 112590848/170498071 [00:09<00:03, 14797251.91it/s]\u001b[A\n",
            " 68% 115671040/170498071 [00:09<00:03, 14282882.23it/s]\u001b[A\n",
            " 70% 118784000/170498071 [00:09<00:03, 14455355.25it/s]\u001b[A\n",
            " 71% 121798656/170498071 [00:09<00:03, 14309922.55it/s]\u001b[A\n",
            " 73% 124911616/170498071 [00:10<00:03, 14403399.47it/s]\u001b[A\n",
            " 75% 128057344/170498071 [00:10<00:02, 14571980.18it/s]\u001b[A\n",
            " 77% 131170304/170498071 [00:10<00:02, 14773323.73it/s]\u001b[A\n",
            " 79% 134316032/170498071 [00:10<00:02, 14677998.27it/s]\u001b[A\n",
            " 81% 137428992/170498071 [00:10<00:02, 14921897.48it/s]\u001b[A\n",
            " 82% 140574720/170498071 [00:11<00:02, 14881724.61it/s]\u001b[A\n",
            " 84% 143687680/170498071 [00:11<00:01, 14969839.64it/s]\u001b[A\n",
            " 86% 146833408/170498071 [00:11<00:01, 14818816.83it/s]\u001b[A\n",
            " 88% 149946368/170498071 [00:11<00:01, 14939506.81it/s]\u001b[A\n",
            " 90% 152666112/170498071 [00:11<00:01, 17019769.58it/s]\u001b[A\n",
            " 91% 154533888/170498071 [00:11<00:01, 15447453.60it/s]\u001b[A\n",
            " 92% 156205056/170498071 [00:12<00:01, 14155042.93it/s]\u001b[A\n",
            " 93% 158105600/170498071 [00:12<00:00, 15140204.63it/s]\u001b[A\n",
            " 94% 159711232/170498071 [00:12<00:00, 13533545.99it/s]\u001b[A\n",
            " 95% 162299904/170498071 [00:12<00:00, 14506341.88it/s]\u001b[A\n",
            " 96% 164003840/170498071 [00:12<00:00, 15038726.05it/s]\u001b[A\n",
            " 97% 165576704/170498071 [00:12<00:00, 13202365.15it/s]\u001b[A\n",
            " 99% 168525824/170498071 [00:12<00:00, 15072860.67it/s]\u001b[A\n",
            "100% 170498071/170498071 [00:13<00:00, 13064868.18it/s]\n",
            "Extracting /data/huy/cifar10/cifar-10-python.tar.gz to /data/huy/cifar10\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Files already downloaded and verified\n",
            "Epoch 0: 100% 196/196 [00:24<00:00,  7.86it/s, v_num=0, loss/train=1.260]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 15.54it/s]\u001b[A\n",
            "Epoch 0: 100% 196/196 [00:27<00:00,  7.08it/s, v_num=0, loss/train=1.260, loss/val=1.390, acc/val=0.489]\n",
            "Epoch 1: 100% 196/196 [00:25<00:00,  7.73it/s, v_num=0, loss/train=1.180, loss/val=1.390, acc/val=0.489]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 15.22it/s]\u001b[A\n",
            "Epoch 1: 100% 196/196 [00:28<00:00,  6.94it/s, v_num=0, loss/train=1.180, loss/val=1.070, acc/val=0.618]\n",
            "Epoch 2: 100% 196/196 [00:25<00:00,  7.54it/s, v_num=0, loss/train=1.050, loss/val=1.070, acc/val=0.618]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 14.87it/s]\u001b[A\n",
            "Epoch 2: 100% 196/196 [00:28<00:00,  6.80it/s, v_num=0, loss/train=1.050, loss/val=1.200, acc/val=0.604]\n",
            "Epoch 3: 100% 196/196 [00:25<00:00,  7.57it/s, v_num=0, loss/train=1.040, loss/val=1.200, acc/val=0.604]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 16.75it/s]\u001b[A\n",
            "Epoch 3: 100% 196/196 [00:28<00:00,  6.83it/s, v_num=0, loss/train=1.040, loss/val=0.871, acc/val=0.706]\n",
            "Epoch 4: 100% 196/196 [00:26<00:00,  7.27it/s, v_num=0, loss/train=0.669, loss/val=0.871, acc/val=0.706]\n",
            "Validation: 0it [00:00, ?it/s]\u001b[A\n",
            "Validation:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:   0% 0/40 [00:00<?, ?it/s]\u001b[A\n",
            "Validation DataLoader 0:  50% 20/40 [00:01<00:01, 16.52it/s]\u001b[A\n",
            "Epoch 4: 100% 196/196 [00:29<00:00,  6.55it/s, v_num=0, loss/train=0.669, loss/val=0.845, acc/val=0.717]\n",
            "Epoch 4: 100% 196/196 [00:29<00:00,  6.55it/s, v_num=0, loss/train=0.669, loss/val=0.845, acc/val=0.717]`Trainer.fit` stopped: `max_epochs=5` reached.\n",
            "Epoch 4: 100% 196/196 [00:30<00:00,  6.38it/s, v_num=0, loss/train=0.669, loss/val=0.845, acc/val=0.717]\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py:148: UserWarning: `.test(ckpt_path=None)` was called without a model. The best model of the previous `fit` call will be used. You can pass `.test(ckpt_path='best')` to use the best model or `.test(ckpt_path='last')` to use the last model. If you pass a value, this warning will be silenced.\n",
            "  rank_zero_warn(\n",
            "Restoring states from the checkpoint path at cifar10/vgg16_bn/version_0/checkpoints/epoch=4-step=980.ckpt\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "Loaded model weights from the checkpoint at cifar10/vgg16_bn/version_0/checkpoints/epoch=4-step=980.ckpt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/PyTorch_CIFAR10/train.py\", line 92, in <module>\n",
            "    main(args)\n",
            "  File \"/content/PyTorch_CIFAR10/train.py\", line 52, in main\n",
            "    trainer.test()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 737, in test\n",
            "    return call._call_and_handle_interrupt(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 42, in _call_and_handle_interrupt\n",
            "    return trainer_fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 780, in _test_impl\n",
            "    results = self._run(model, ckpt_path=ckpt_path)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 975, in _run\n",
            "    results = self._run_stage()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\", line 1011, in _run_stage\n",
            "    return self._evaluation_loop.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/utilities.py\", line 177, in _decorator\n",
            "    return loop_run(self, *args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\", line 98, in run\n",
            "    self.setup_data()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/evaluation_loop.py\", line 150, in setup_data\n",
            "    dataloaders = _request_dataloader(source)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 330, in _request_dataloader\n",
            "    return data_source.dataloader()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\", line 297, in dataloader\n",
            "    return call._call_lightning_module_hook(self.instance.trainer, self.name, pl_module=self.instance)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/call.py\", line 140, in _call_lightning_module_hook\n",
            "    output = fn(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/hooks.py\", line 445, in test_dataloader\n",
            "    raise MisconfigurationException(\"`test_dataloader` must be implemented to be used with the Lightning Trainer\")\n",
            "lightning_fabric.utilities.exceptions.MisconfigurationException: `test_dataloader` must be implemented to be used with the Lightning Trainer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --test_phase 1 --pretrained 1 --classifier vgg16_bn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-NVnupzKfna",
        "outputId": "abf32822-63b5-4d57-dc7a-08e4db62a773"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Global seed set to 0\n",
            "GPU available: True (cuda), used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "HPU available: False, using: 0 HPUs\n",
            "Files already downloaded and verified\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Missing logger folder: /content/PyTorch_CIFAR10/lightning_logs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "2023-06-24 16:09:04.407241: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-06-24 16:09:05.390336: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Testing DataLoader 0: 100% 40/40 [00:03<00:00, 11.01it/s]\n",
            "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
            "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
            "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
            "│\u001b[36m \u001b[0m\u001b[36m        acc/test         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8712000250816345    \u001b[0m\u001b[35m \u001b[0m│\n",
            "│\u001b[36m \u001b[0m\u001b[36m        loss/test        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.46442827582359314   \u001b[0m\u001b[35m \u001b[0m│\n",
            "└───────────────────────────┴───────────────────────────┘\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/PyTorch_CIFAR10/train.py\", line 92, in <module>\n",
            "    main(args)\n",
            "  File \"/content/PyTorch_CIFAR10/train.py\", line 59, in main\n",
            "    os.makedirs(best_checkpoint_dir, exist_ok=True)\n",
            "  File \"/usr/lib/python3.10/os.py\", line 225, in makedirs\n",
            "    mkdir(name, mode)\n",
            "FileNotFoundError: [Errno 2] No such file or directory: ''\n"
          ]
        }
      ]
    }
  ]
}